{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import gzip\n", "import os\n", "import platform\n", "import pickle"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class DatasetLoad(object):\n", "\tdef __init__(self, dataSetName, isIID):\n", "\t\tself.name = dataSetName\n", "\t\tself.train_data = None\n", "\t\tself.train_label = None\n", "\t\tself.train_data_size = None\n", "\t\tself.test_data = None\n", "\t\tself.test_label = None\n", "\t\tself.test_data_size = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tself._index_in_train_epoch = 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tif self.name == 'mnist':\n", "\t\t\tself.mnistDataSetConstruct(isIID)\n", "\t\telse:\n", "\t\t\tpass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tdef mnistDataSetConstruct(self, isIID):\n", "\t\tdata_dir = 'data/MNIST'\n", "\t\ttrain_images_path = os.path.join(data_dir, 'train-images-idx3-ubyte.gz')\n", "\t\ttrain_labels_path = os.path.join(data_dir, 'train-labels-idx1-ubyte.gz')\n", "\t\ttest_images_path = os.path.join(data_dir, 't10k-images-idx3-ubyte.gz')\n", "\t\ttest_labels_path = os.path.join(data_dir, 't10k-labels-idx1-ubyte.gz')\n", "\t\ttrain_images = extract_images(train_images_path)\n", "\t\ttrain_labels = extract_labels(train_labels_path)\n", "\t\ttest_images = extract_images(test_images_path)\n", "\t\ttest_labels = extract_labels(test_labels_path)\n", "\t\t# CPU reduce size\n", "\t\t# train_images = train_images[:60]\n", "\t\t# train_labels = train_labels[:60]\n", "\t\t# test_images = test_images[:60]\n", "\t\t# test_labels = test_labels[:60]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t# 60000 data points\n", "\t\tassert train_images.shape[0] == train_labels.shape[0]\n", "\t\tassert test_images.shape[0] == test_labels.shape[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tself.train_data_size = train_images.shape[0]\n", "\t\tself.test_data_size = test_images.shape[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tassert train_images.shape[3] == 1\n", "\t\tassert test_images.shape[3] == 1\n", "\t\ttrain_images = train_images.reshape(train_images.shape[0], train_images.shape[1] * train_images.shape[2])\n", "\t\ttest_images = test_images.reshape(test_images.shape[0], test_images.shape[1] * test_images.shape[2])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\ttrain_images = train_images.astype(np.float32)\n", "\t\ttrain_images = np.multiply(train_images, 1.0 / 255.0)\n", "\t\ttest_images = test_images.astype(np.float32)\n", "\t\ttest_images = np.multiply(test_images, 1.0 / 255.0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tif isIID:\n", "\t\t\torder = np.arange(self.train_data_size)\n", "\t\t\tnp.random.shuffle(order)\n", "\t\t\tself.train_data = train_images[order]\n", "\t\t\tself.train_label = train_labels[order]\n", "\t\telse:\n", "\t\t\tlabels = np.argmax(train_labels, axis=1)\n", "\t\t\torder = np.argsort(labels)\n", "\t\t\tself.train_data = train_images[order]\n", "\t\t\tself.train_label = train_labels[order]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tself.test_data = test_images\n", "\t\tself.test_label = test_labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _read32(bytestream):\n", "\tdt = np.dtype(np.uint32).newbyteorder('>')\n", "\treturn np.frombuffer(bytestream.read(4), dtype=dt)[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_images(filename):\n", "\t\"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\"\"\"\n", "\tprint('Extracting', filename)\n", "\twith gzip.open(filename) as bytestream:\n", "\t\tmagic = _read32(bytestream)\n", "\t\tif magic != 2051:\n", "\t\t\traise ValueError(\n", "\t\t\t\t\t'Invalid magic number %d in MNIST image file: %s' %\n", "\t\t\t\t\t(magic, filename))\n", "\t\tnum_images = _read32(bytestream)\n", "\t\trows = _read32(bytestream)\n", "\t\tcols = _read32(bytestream)\n", "\t\tbuf = bytestream.read(rows * cols * num_images)\n", "\t\tdata = np.frombuffer(buf, dtype=np.uint8)\n", "\t\tdata = data.reshape(num_images, rows, cols, 1)\n", "\t\treturn data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def dense_to_one_hot(labels_dense, num_classes=10):\n", "\t\"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n", "\tnum_labels = labels_dense.shape[0]\n", "\tindex_offset = np.arange(num_labels) * num_classes\n", "\tlabels_one_hot = np.zeros((num_labels, num_classes))\n", "\tlabels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n", "\treturn labels_one_hot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_labels(filename):\n", "\t\"\"\"Extract the labels into a 1D uint8 numpy array [index].\"\"\"\n", "\tprint('Extracting', filename)\n", "\twith gzip.open(filename) as bytestream:\n", "\t\tmagic = _read32(bytestream)\n", "\t\tif magic != 2049:\n", "\t\t\traise ValueError(\n", "\t\t\t\t\t'Invalid magic number %d in MNIST label file: %s' %\n", "\t\t\t\t\t(magic, filename))\n", "\t\tnum_items = _read32(bytestream)\n", "\t\tbuf = bytestream.read(num_items)\n", "\t\tlabels = np.frombuffer(buf, dtype=np.uint8)\n", "\t\treturn dense_to_one_hot(labels)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__==\"__main__\":\n", "\t'test data set'\n", "\tmnistDataSet = GetDataSet('mnist', True) # test NON-IID\n", "\tif type(mnistDataSet.train_data) is np.ndarray and type(mnistDataSet.test_data) is np.ndarray and \\\n", "\t\t\ttype(mnistDataSet.train_label) is np.ndarray and type(mnistDataSet.test_label) is np.ndarray:\n", "\t\tprint('the type of data is numpy ndarray')\n", "\telse:\n", "\t\tprint('the type of data is not numpy ndarray')\n", "\tprint('the shape of the train data set is {}'.format(mnistDataSet.train_data.shape))\n", "\tprint('the shape of the test data set is {}'.format(mnistDataSet.test_data.shape))\n", "\tprint(mnistDataSet.train_label[0:100], mnistDataSet.train_label[11000:11100])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["add Gussian Noise to dataset<br>\n", "https://discuss.pytorch.org/t/how-to-add-noise-to-mnist-dataset-when-using-pytorch/59745"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class AddGaussianNoise(object):\n", "\tdef __init__(self, mean=0., std=1.):\n", "\t\tself.std = std\n", "\t\tself.mean = mean\n", "\t\t\n", "\tdef __call__(self, tensor):\n", "\t\treturn tensor + torch.randn(tensor.size()) * self.std + self.mean\n", "\t\n", "\tdef __repr__(self):\n", "\t\treturn self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}